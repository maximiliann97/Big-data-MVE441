{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977ea02a",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e25f712a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82,)\n",
      "(82, 3000)\n"
     ]
    }
   ],
   "source": [
    "labels = list()\n",
    "\n",
    "with open('Cancerdata.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        line = line.split('\\t')\n",
    "        line = [item.rstrip() for item in line]\n",
    "        line[0] = float(line[0].strip('\"'))\n",
    "        line[1:] = [float(x) for x in line[1:]]\n",
    "        line = np.asarray(line)\n",
    "        \n",
    "        # Append labels\n",
    "        labels.append(int(line[1]))\n",
    "        \n",
    "        # Create the data np.array with first observation\n",
    "        # Vstack the rest of the observations to the newly created data matrix\n",
    "        observation = line[1:]\n",
    "        if i == 1:\n",
    "            data = observation\n",
    "        else:\n",
    "            data = np.vstack((data, observation))\n",
    "        \n",
    "labels = np.asarray(labels)\n",
    "\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb1061",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "### Dimension and feature selection techniques suited for unsupervised clustering tasks\n",
    "\n",
    "1. Principal Component Analysis (PCA)\n",
    "2. Independent Component Analysis (ICA)\n",
    "3. Random Projections\n",
    "4. Feature Selection based on Clustering Quality\n",
    "5. Recursive Feature Elimination (RFE)\n",
    "\n",
    "Principal Component Analysis (PCA): PCA is a technique that reduces the dimensionality of the data by identifying the most important features that capture the most variance in the data. PCA is a powerful technique for feature selection, as it can often reduce the number of features required for clustering while still retaining the important information.\n",
    "\n",
    "Independent Component Analysis (ICA): ICA is a technique that separates the data into independent sources based on statistical properties. ICA can be used for feature selection by identifying the features that have the most independent information, which can help to remove redundant or noisy features.\n",
    "\n",
    "Random Projections: Random projections is a technique that can be used to reduce the dimensionality of the data by projecting the data onto a lower-dimensional subspace. Random projections can be used for feature selection by identifying the most important dimensions that capture the most variance in the data.\n",
    "\n",
    "Feature Selection based on Clustering Quality: This approach selects the features that produce the best clustering results. This method works by selecting a subset of features and evaluating the clustering performance with different clustering algorithms, and selecting the subset of features that results in the best clustering performance.\n",
    "\n",
    "Recursive Feature Elimination (RFE): RFE is a feature selection method that selects features by recursively considering smaller and smaller subsets of features. RFE works by training a model on the full set of features, ranking the importance of the features, and then eliminating the least important feature. This process is repeated until a predetermined number of features is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9fa4a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.125      -1.08947971 -0.88033154 ...  1.33720657  0.68278636\n",
      "  -0.083798  ]\n",
      " [ 0.69230769 -1.0089447  -0.92100112 ...  1.70078472  0.33725468\n",
      "   0.03819142]\n",
      " [ 2.         -1.1133637  -0.80018155 ...  2.18587067  0.3439222\n",
      "   0.12238922]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, n_init=\"auto\").fit(data)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c52303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_venv",
   "language": "python",
   "name": "bigdata_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
