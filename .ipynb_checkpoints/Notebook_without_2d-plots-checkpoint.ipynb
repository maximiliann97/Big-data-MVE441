{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5cc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8902c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145460, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get The data\n",
    "raw_data = pd.read_csv(('weatherAUS.csv'))\n",
    "raw_data.info()\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25277581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking all the null vals\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c523f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling all the null values from the numerical data with their respective mean value\n",
    "# This method is taken from a kaggle code, but we have some different names, but \n",
    "# I think i'ts okey to use the same method.\n",
    "\n",
    "raw_data['MinTemp']=raw_data['MinTemp'].fillna(raw_data['MinTemp'].mean())\n",
    "raw_data['MaxTemp']=raw_data['MaxTemp'].fillna(raw_data['MaxTemp'].mean())\n",
    "raw_data['Rainfall']=raw_data['Rainfall'].fillna(raw_data['Rainfall'].mean())\n",
    "raw_data['Evaporation']=raw_data['Evaporation'].fillna(raw_data['Evaporation'].mean())\n",
    "raw_data['Sunshine']=raw_data['Sunshine'].fillna(raw_data['Sunshine'].mean())\n",
    "raw_data['WindGustSpeed']=raw_data['WindGustSpeed'].fillna(raw_data['WindGustSpeed'].mean())\n",
    "raw_data['WindSpeed9am']=raw_data['WindSpeed9am'].fillna(raw_data['WindSpeed9am'].mean())\n",
    "raw_data['WindSpeed3pm']=raw_data['WindSpeed3pm'].fillna(raw_data['WindSpeed3pm'].mean())\n",
    "raw_data['Humidity9am']=raw_data['Humidity9am'].fillna(raw_data['Humidity9am'].mean())\n",
    "raw_data['Humidity3pm']=raw_data['Humidity3pm'].fillna(raw_data['Humidity3pm'].mean())\n",
    "raw_data['Pressure9am']=raw_data['Pressure9am'].fillna(raw_data['Pressure9am'].mean())\n",
    "raw_data['Pressure3pm']=raw_data['Pressure3pm'].fillna(raw_data['Pressure3pm'].mean())\n",
    "raw_data['Cloud9am']=raw_data['Cloud9am'].fillna(raw_data['Cloud9am'].mean())\n",
    "raw_data['Cloud3pm']=raw_data['Cloud3pm'].fillna(raw_data['Cloud3pm'].mean())\n",
    "raw_data['Temp9am']=raw_data['Temp9am'].fillna(raw_data['Temp9am'].mean())\n",
    "raw_data['Temp3pm']=raw_data['Temp3pm'].fillna(raw_data['Temp3pm'].mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbad738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling all the null values from the categorical data with their most frequently occurring value\n",
    "raw_data['WindGustDir']=raw_data['WindGustDir'].fillna(raw_data['WindGustDir'].mode()[0])\n",
    "raw_data['WindDir9am']=raw_data['WindDir9am'].fillna(raw_data['WindDir9am'].mode()[0])\n",
    "raw_data['WindDir3pm']=raw_data['WindDir3pm'].fillna(raw_data['WindDir3pm'].mode()[0])\n",
    "raw_data['RainToday']=raw_data['RainToday'].fillna(raw_data['RainToday'].mode()[0])\n",
    "raw_data['RainTomorrow']=raw_data['RainTomorrow'].fillna(raw_data['RainTomorrow'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa8c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine   \n",
       "0  2008-12-01   Albury     13.4     22.9       0.6     5.468232  7.611178  \\\n",
       "1  2008-12-02   Albury      7.4     25.1       0.0     5.468232  7.611178   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0     5.468232  7.611178   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0     5.468232  7.611178   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0     5.468232  7.611178   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm   \n",
       "0           W           44.0          W  ...        71.0         22.0  \\\n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday   \n",
       "0       1007.7       1007.1  8.000000   4.50993     16.9     21.8         No  \\\n",
       "1       1010.6       1007.8  4.447461   4.50993     17.2     24.3         No   \n",
       "2       1007.6       1008.7  4.447461   2.00000     21.0     23.2         No   \n",
       "3       1017.6       1012.8  4.447461   4.50993     18.1     26.5         No   \n",
       "4       1010.8       1006.0  7.000000   8.00000     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "094be73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making categorical yes and no to 1 and 0 respectivevly\n",
    "raw_data['RainTomorrow']=raw_data['RainTomorrow'].map({'Yes':1,'No':0})\n",
    "raw_data['RainToday']=raw_data['RainToday'].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d3c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from date convert to day, month\n",
    "raw_data['Date']=pd.to_datetime(raw_data['Date'])\n",
    "raw_data['day']=raw_data['Date'].dt.day\n",
    "raw_data['month']=raw_data['Date'].dt.month\n",
    "#drop date\n",
    "raw_data.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d039fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.50993</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>...</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir   \n",
       "0   Albury     13.4     22.9       0.6     5.468232  7.611178           W  \\\n",
       "1   Albury      7.4     25.1       0.0     5.468232  7.611178         WNW   \n",
       "2   Albury     12.9     25.7       0.0     5.468232  7.611178         WSW   \n",
       "3   Albury      9.2     28.0       0.0     5.468232  7.611178          NE   \n",
       "4   Albury     17.5     32.3       1.0     5.468232  7.611178           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  ...  Pressure9am  Pressure3pm   \n",
       "0           44.0          W        WNW  ...       1007.7       1007.1  \\\n",
       "1           44.0        NNW        WSW  ...       1010.6       1007.8   \n",
       "2           46.0          W        WSW  ...       1007.6       1008.7   \n",
       "3           24.0         SE          E  ...       1017.6       1012.8   \n",
       "4           41.0        ENE         NW  ...       1010.8       1006.0   \n",
       "\n",
       "   Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  day  month  \n",
       "0  8.000000   4.50993     16.9     21.8          0             0    1     12  \n",
       "1  4.447461   4.50993     17.2     24.3          0             0    2     12  \n",
       "2  4.447461   2.00000     21.0     23.2          0             0    3     12  \n",
       "3  4.447461   4.50993     18.1     26.5          0             0    4     12  \n",
       "4  7.000000   8.00000     17.8     29.7          0             0    5     12  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e293db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "raw_data=pd.get_dummies(raw_data)\n",
    "index = raw_data.columns.get_loc('RainTomorrow')\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddbd4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed   \n",
       "0     13.4     22.9       0.6     5.468232  7.611178           44.0  \\\n",
       "1      7.4     25.1       0.0     5.468232  7.611178           44.0   \n",
       "2     12.9     25.7       0.0     5.468232  7.611178           46.0   \n",
       "3      9.2     28.0       0.0     5.468232  7.611178           24.0   \n",
       "4     17.5     32.3       1.0     5.468232  7.611178           41.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW   \n",
       "0          20.0          24.0         71.0         22.0  ...           False  \\\n",
       "1           4.0          22.0         44.0         25.0  ...           False   \n",
       "2          19.0          26.0         38.0         30.0  ...           False   \n",
       "3          11.0           9.0         45.0         16.0  ...           False   \n",
       "4           7.0          20.0         82.0         33.0  ...           False   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW   \n",
       "0          False         False          False           False           False  \\\n",
       "1          False         False          False           False           False   \n",
       "2          False         False          False           False           False   \n",
       "3          False         False          False           False           False   \n",
       "4           True         False          False           False           False   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0          False         False            True           False  \n",
       "1          False         False           False            True  \n",
       "2          False         False           False            True  \n",
       "3          False         False           False           False  \n",
       "4          False         False           False           False  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a8a7e",
   "metadata": {},
   "source": [
    "### Principal components analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a52664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "raw_data_pp = StandardScaler().fit_transform(raw_data)\n",
    "pca = PCA().fit(raw_data_pp)\n",
    "\n",
    "# The PCA object offers convenient ways of accessing the\n",
    "# principal directions and explained variance\n",
    "pca.components_;\n",
    "pca.explained_variance_;\n",
    "\n",
    "# To get the principal components, the `transform` method of the\n",
    "# PCA object can be used\n",
    "principal_components_pca = pca.transform(raw_data_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae0bdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.plot(np.arange(1, len(pca.explained_variance_) + 1), pca.explained_variance_, 'ok', markersize=2)\n",
    "ax.axvline(6, linestyle=\"dashed\", color=\"red\", linewidth=1)\n",
    "\n",
    "ax.set_xlabel(\"Principal Component\")\n",
    "ax.set_ylabel(\"Explained Variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d9f49",
   "metadata": {},
   "source": [
    "Looking at the screen plot, a good cut-off is after 5 principal components, since 5 and 6 are very close. So we could keep the first six columns of principal_components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33ec1f",
   "metadata": {},
   "source": [
    "### Split and mislabel the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cd2e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#label are the value we want to predict\n",
    "labels=raw_data['RainTomorrow']\n",
    "pca = PCA(n_components=5)\n",
    "levels = np.linspace(0, 0.7, num=8)\n",
    "iterations = 10\n",
    "\n",
    "def split_mislabel(data, labels, level):\n",
    "    data = data.drop('RainTomorrow',axis=1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    # Split to get unaltered test set\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(data, labels, stratify=labels, test_size=0.20)\n",
    "    \n",
    "    if level == 0:\n",
    "        train_features_pca = pca.fit_transform(train_features)\n",
    "        test_features_pca = pca.fit_transform(test_features)\n",
    "    \n",
    "    else:\n",
    "        # Calculate the number of labels to swap based on the percentage\n",
    "        n_swap = int(len(train_labels) * level)\n",
    "\n",
    "        # Randomly select the indices of the labels to be swapped\n",
    "        swap_indices = np.random.choice(len(train_labels), n_swap, replace=False)\n",
    "        train_labels.iloc[swap_indices] = 1 - train_labels.iloc[swap_indices]\n",
    "\n",
    "\n",
    "        train_features_pca = pca.fit_transform(train_features)\n",
    "        test_features_pca = pca.fit_transform(test_features)\n",
    "\n",
    "\n",
    "    return train_features_pca, test_features_pca, train_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cb2d3",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6ce7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4751b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82798708 0.82627183 0.8212567  0.79295339 0.70145745 0.49852537\n",
      " 0.30180118 0.20694349]\n"
     ]
    }
   ],
   "source": [
    "best_k = 31 #Best k found to be 31 through cross-validation\n",
    "knn_f1_scores = np.zeros((len(levels), iterations))\n",
    "knn_accuracy_scores = np.zeros((len(levels), iterations))\n",
    "knn_roc_auc_scores = np.zeros((len(levels), iterations))\n",
    "\n",
    "for i, level in enumerate(levels):\n",
    "    for j in range(iterations):\n",
    "        train_features_pca, test_features_pca, train_labels, test_labels = split_mislabel(raw_data, labels, level)\n",
    "\n",
    "        # Train a K-nearest neighbor classifier on the projected data for the three different levels\n",
    "        knn = KNeighborsClassifier(n_neighbors=best_k).fit(train_features_pca, train_labels)\n",
    "        \n",
    "        # predict the class labels for the test set\n",
    "        y_pred = knn.predict(test_features_pca)\n",
    "        \n",
    "        # compute the evaluation metrics and append to the respective list\n",
    "        knn_f1_scores[i, j] = f1_score(test_labels, y_pred)\n",
    "        knn_accuracy_scores[i, j] = accuracy_score(test_labels, y_pred)\n",
    "        knn_roc_auc_scores[i, j] = roc_auc_score(test_labels, y_pred)\n",
    "    \n",
    "\n",
    "knn_f1 = np.mean(knn_f1_scores, axis=1)\n",
    "knn_accuracy = np.mean(knn_accuracy_scores, axis=1)\n",
    "knn_roc_auc = np.mean(knn_roc_auc_scores, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1c73c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49896009 0.49976512 0.4980184  0.46029362 0.39594526 0.30207378\n",
      " 0.26166613 0.24782277]\n",
      "[0.82798708 0.82627183 0.8212567  0.79295339 0.70145745 0.49852537\n",
      " 0.30180118 0.20694349]\n",
      "[0.67110631 0.67184171 0.67161515 0.65282639 0.6097957  0.49734056\n",
      " 0.39633062 0.34697781]\n"
     ]
    }
   ],
   "source": [
    "print(knn_f1)\n",
    "print(knn_accuracy)\n",
    "print(knn_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6722345",
   "metadata": {},
   "source": [
    "***Performing cross validation to get best k value***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0387d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:76\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mKNeighborsClassifier(k, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_features, train_labels)\n\u001b[1;32m---> 14\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m meaned_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_roc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meaned_score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:115\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[1;32m--> 115\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:276\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(\n\u001b[0;32m    279\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs\n\u001b[0;32m    280\u001b[0m         )\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:78\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[method]\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     cache[method] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    820\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[1;32m--> 824\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[0;32m    836\u001b[0m ):\n\u001b[0;32m    837\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[0;32m    838\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[0;32m    839\u001b[0m     )\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:277\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    290\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    291\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    298\u001b[0m     )\n",
      "File \u001b[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx:95\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "k_s = np.linspace(1, 50, num=50, dtype=int)\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "iteration = 0\n",
    "scoring = ['f1_macro', 'accuracy', 'roc_auc']\n",
    "\n",
    "for k in k_s:\n",
    "    iteration += 1\n",
    "    print(f'Iteration {iteration}')\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier(k, weights='uniform')\n",
    "    model.fit(train_features_pca0, train_labels)\n",
    "    cv_scores = cross_validate(model, train_features_pca0, train_labels, cv=10, scoring=scoring)\n",
    "    meaned_score = np.mean(cv_scores['test_f1_macro']+cv_scores['test_accuracy']+cv_scores['test_roc_auc'])\n",
    "    \n",
    "    if meaned_score > best_score:\n",
    "        best_score = np.mean(cv_scores['test_f1_macro']+cv_scores['test_accuracy']+cv_scores['test_roc_auc'])\n",
    "        best_k = k\n",
    "        print(f\"Current best k = {best_k}, F1 Macro: {np.mean(cv_scores['test_f1_macro'])}, Accuracy: {np.mean(cv_scores['test_accuracy'])}, ROC AUC: {np.mean(cv_scores['test_roc_auc'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0777d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fabcf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fb04c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_f1_scores = np.zeros((len(levels), iterations))\n",
    "logreg_accuracy_scores = np.zeros((len(levels), iterations))\n",
    "logreg_roc_auc_scores = np.zeros((len(levels), iterations))\n",
    "\n",
    "for i, level in enumerate(levels):\n",
    "    for j in range(iterations):\n",
    "        train_features_pca, test_features_pca, train_labels, test_labels = split_mislabel(raw_data, labels, level)\n",
    "        \n",
    "        # Train a K-nearest neighbor classifier on the projected data for the three different levels\n",
    "        logreg = make_pipeline(StandardScaler(), LogisticRegression()).fit(train_features_pca, train_labels)\n",
    "        # predict the class labels for the test set\n",
    "        y_pred = logreg.predict(test_features_pca)\n",
    "        # compute the evaluation metrics and append to the respective list\n",
    "        logreg_f1_scores[i, j] = f1_score(test_labels, y_pred)\n",
    "        logreg_accuracy_scores[i, j] = accuracy_score(test_labels, y_pred)\n",
    "        logreg_roc_auc_scores[i, j] = roc_auc_score(test_labels, y_pred)\n",
    "    \n",
    "\n",
    "logreg_f1 = np.mean(logreg_f1_scores, axis=1)\n",
    "logreg_accuracy = np.mean(logreg_accuracy_scores, axis=1)\n",
    "logreg_roc_auc = np.mean(logreg_roc_auc_scores, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "739ae9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50802238 0.47156668 0.45638308 0.43456547 0.41783018 0.32865151\n",
      " 0.26598644 0.26194828]\n",
      "[0.82894954 0.82451189 0.82292039 0.81998144 0.81804964 0.53807576\n",
      " 0.17661556 0.17408566]\n",
      "[0.67594291 0.65668844 0.64909064 0.63884713 0.63133047 0.54547639\n",
      " 0.35808242 0.35206162]\n"
     ]
    }
   ],
   "source": [
    "print(logreg_f1)\n",
    "print(logreg_accuracy)\n",
    "print(logreg_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adb632",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cdecc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "LDA_f1_scores = np.zeros((len(levels), iterations))\n",
    "LDA_accuracy_scores = np.zeros((len(levels), iterations))\n",
    "LDA_roc_auc_scores = np.zeros((len(levels), iterations))\n",
    "\n",
    "for i, level in enumerate(levels):\n",
    "    for j in range(iterations):\n",
    "        train_features_pca, test_features_pca, train_labels, test_labels = split_mislabel(raw_data, labels, level)\n",
    "        \n",
    "        # Train a K-nearest neighbor classifier on the projected data for the three different levels\n",
    "        LDA = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')).fit(train_features_pca, train_labels)\n",
    "        # predict the class labels for the test set\n",
    "        y_pred = LDA.predict(test_features_pca)\n",
    "        # compute the evaluation metrics and append to the respective list\n",
    "        LDA_f1_scores[i, j] = f1_score(test_labels, y_pred)\n",
    "        LDA_accuracy_scores[i, j] = accuracy_score(test_labels, y_pred)\n",
    "        LDA_roc_auc_scores[i, j] = roc_auc_score(test_labels, y_pred)\n",
    "    \n",
    "\n",
    "LDA_f1 = np.mean(LDA_f1_scores, axis=1)\n",
    "LDA_accuracy = np.mean(LDA_accuracy_scores, axis=1)\n",
    "LDA_roc_auc = np.mean(LDA_roc_auc_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f373d273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48609782 0.48995873 0.47793699 0.44146024 0.42214508 0.29034609\n",
      " 0.26780381 0.26238883]\n",
      "[0.8208889  0.82611027 0.82725148 0.82177575 0.81829025 0.48638457\n",
      " 0.17753334 0.17526124]\n",
      "[0.66481784 0.66616947 0.65964441 0.64217956 0.63306434 0.49295193\n",
      " 0.36062791 0.35304569]\n"
     ]
    }
   ],
   "source": [
    "print(LDA_f1)\n",
    "print(LDA_accuracy)\n",
    "print(LDA_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79d81c",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd313c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fea849",
   "metadata": {},
   "source": [
    "***Performing crossvalidation to get best nr of trees to use***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05880264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Current best nr of trees = 1, F1 Macro: 0.6542927305641195, Accuracy: 0.760123092164066, ROC AUC: 0.6564681468295679\n",
      "Iteration 2\n",
      "Current best nr of trees = 2, F1 Macro: 0.6455703174258264, Accuracy: 0.8061924153861012, ROC AUC: 0.709187527006917\n",
      "Iteration 3\n",
      "Current best nr of trees = 3, F1 Macro: 0.6872406974984864, Accuracy: 0.7976333888130146, ROC AUC: 0.7375263507035443\n",
      "Iteration 4\n",
      "Current best nr of trees = 4, F1 Macro: 0.677004529046065, Accuracy: 0.8160662861813941, ROC AUC: 0.7546343957620153\n",
      "Iteration 5\n",
      "Current best nr of trees = 5, F1 Macro: 0.6987794814803229, Accuracy: 0.8109274205185845, ROC AUC: 0.765636796670098\n",
      "Iteration 6\n",
      "Current best nr of trees = 6, F1 Macro: 0.6891527276786751, Accuracy: 0.8209731406677998, ROC AUC: 0.7744866205238894\n",
      "Iteration 7\n",
      "Current best nr of trees = 7, F1 Macro: 0.7038533359794327, Accuracy: 0.8172350040247214, ROC AUC: 0.7806402040921359\n",
      "Iteration 8\n",
      "Current best nr of trees = 8, F1 Macro: 0.695068478443347, Accuracy: 0.8233363488095382, ROC AUC: 0.785482794165201\n",
      "Iteration 9\n",
      "Current best nr of trees = 9, F1 Macro: 0.7072790900904867, Accuracy: 0.8210676689639289, ROC AUC: 0.7900298890721216\n",
      "Iteration 10\n",
      "Current best nr of trees = 10, F1 Macro: 0.7001757452424318, Accuracy: 0.8255878022156009, ROC AUC: 0.7933194217942269\n",
      "Iteration 11\n",
      "Current best nr of trees = 11, F1 Macro: 0.7091965643585927, Accuracy: 0.823319133447613, ROC AUC: 0.7961676169235771\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Current best nr of trees = 13, F1 Macro: 0.7105698507010423, Accuracy: 0.8249862726117513, ROC AUC: 0.8004834172508005\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Current best nr of trees = 15, F1 Macro: 0.71157146083239, Accuracy: 0.8263698143328645, ROC AUC: 0.8042914084155257\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Current best nr of trees = 17, F1 Macro: 0.7121912091692366, Accuracy: 0.827504153147907, ROC AUC: 0.8074588500105978\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Current best nr of trees = 19, F1 Macro: 0.7123974878247392, Accuracy: 0.8280627207825303, ROC AUC: 0.8098736101058238\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Current best nr of trees = 21, F1 Macro: 0.7135936121804369, Accuracy: 0.8291712605561976, ROC AUC: 0.8115808373446086\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Current best nr of trees = 23, F1 Macro: 0.7141744077178982, Accuracy: 0.8296095237470672, ROC AUC: 0.8131417904314897\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Current best nr of trees = 25, F1 Macro: 0.7144948827801912, Accuracy: 0.8298759161672802, ROC AUC: 0.8146145903240504\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Current best nr of trees = 27, F1 Macro: 0.7145926313784675, Accuracy: 0.8300134042171117, ROC AUC: 0.8157402105460372\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Current best nr of trees = 29, F1 Macro: 0.7155807207709339, Accuracy: 0.8307610358290741, ROC AUC: 0.816762816417425\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Current best nr of trees = 31, F1 Macro: 0.7149200281377223, Accuracy: 0.8305548059698513, ROC AUC: 0.8177543750436215\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Current best nr of trees = 33, F1 Macro: 0.7152228297672538, Accuracy: 0.8309415220350281, ROC AUC: 0.8183132536505837\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Current best nr of trees = 35, F1 Macro: 0.7153801926568515, Accuracy: 0.8311133905901604, ROC AUC: 0.8190544798372237\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Current best nr of trees = 37, F1 Macro: 0.7153616078536954, Accuracy: 0.8311907367572282, ROC AUC: 0.8195554788478636\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Current best nr of trees = 39, F1 Macro: 0.7158400251061896, Accuracy: 0.831560229336891, ROC AUC: 0.8201322958671993\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Current best nr of trees = 41, F1 Macro: 0.7162091588729265, Accuracy: 0.8319555290815177, ROC AUC: 0.8207828793547769\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Current best nr of trees = 43, F1 Macro: 0.716124038596244, Accuracy: 0.8318953746441167, ROC AUC: 0.821194541340682\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Current best nr of trees = 45, F1 Macro: 0.716208257276423, Accuracy: 0.8321274020676984, ROC AUC: 0.8216409956973451\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Current best nr of trees = 47, F1 Macro: 0.7164779433008357, Accuracy: 0.8322391228320024, ROC AUC: 0.8221128768476692\n",
      "Iteration 48\n",
      "Iteration 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "trees = np.linspace(1, 150, num=150, dtype=int)\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "iteration = 0\n",
    "scoring = ['f1_macro', 'accuracy', 'roc_auc']\n",
    "\n",
    "for t in trees:\n",
    "    iteration += 1\n",
    "    print(f'Iteration {iteration}')\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=t, random_state=42).fit(train_features_pca0, train_labels)\n",
    "    cv_scores = cross_validate(model, train_features_pca0, train_labels, cv=10, scoring=scoring)\n",
    "    meaned_score = np.mean(cv_scores['test_f1_macro']+cv_scores['test_accuracy']+cv_scores['test_roc_auc'])\n",
    "    \n",
    "    if meaned_score > best_score:\n",
    "        best_score = np.mean(cv_scores['test_f1_macro']+cv_scores['test_accuracy']+cv_scores['test_roc_auc'])\n",
    "        best_t = t\n",
    "        print(f\"Current best nr of trees = {best_t}, F1 Macro: {np.mean(cv_scores['test_f1_macro'])}, Accuracy: {np.mean(cv_scores['test_accuracy'])}, ROC AUC: {np.mean(cv_scores['test_roc_auc'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76b160a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(levels):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m----> 7\u001b[0m         train_features_pca, test_features_pca, train_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43msplit_mislabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Train a K-nearest neighbor classifier on the projected data for the three different levels\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         RF \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(train_features_pca, train_labels)\n",
      "Cell \u001b[1;32mIn[61], line 29\u001b[0m, in \u001b[0;36msplit_mislabel\u001b[1;34m(data, labels, level)\u001b[0m\n\u001b[0;32m     25\u001b[0m     swap_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(train_labels), n_swap, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m     train_labels\u001b[38;5;241m.\u001b[39miloc[swap_indices] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m train_labels\u001b[38;5;241m.\u001b[39miloc[swap_indices]\n\u001b[1;32m---> 29\u001b[0m     train_features_pca \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     test_features_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(test_features)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_features_pca, test_features_pca, train_labels, test_labels\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 485\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:949\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmay_share_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_orig\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    950\u001b[0m             array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    951\u001b[0m                 array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    952\u001b[0m             )\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmay_share_memory\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\generic.py:1997\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\n\u001b[0;32m   1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2003\u001b[0m     ):\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\frame.py:1000\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    998\u001b[0m blocks \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[0;32m   1002\u001b[0m arr \u001b[38;5;241m=\u001b[39m blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\frame.py:11360\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11286\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11289\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11290\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11358\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1775\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# much more performant than using to_numpy below\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1775\u001b[0m         rl \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\n\u001b[0;32m   1776\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m   1777\u001b[0m         result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n",
      "File \u001b[1;32m~\\OneDrive\\Dokument\\Chalmers\\Statistical learning for big data\\bigdata_venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:205\u001b[0m, in \u001b[0;36mBlock.mgr_locs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmgr_locs\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockPlacement:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs\n\u001b[0;32m    209\u001b[0m \u001b[38;5;129m@mgr_locs\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmgr_locs\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_mgr_locs: BlockPlacement) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RF_f1_scores = np.zeros((len(levels), iterations))\n",
    "RF_accuracy_scores = np.zeros((len(levels), iterations))\n",
    "RF_roc_auc_scores = np.zeros((len(levels), iterations))\n",
    "\n",
    "for i, level in enumerate(levels):\n",
    "    for j in range(iterations):\n",
    "        train_features_pca, test_features_pca, train_labels, test_labels = split_mislabel(raw_data, labels, level)\n",
    "        \n",
    "        # Train a K-nearest neighbor classifier on the projected data for the three different levels\n",
    "        RF = RandomForestClassifier(n_estimators=21).fit(train_features_pca, train_labels)\n",
    "        # predict the class labels for the test set\n",
    "        y_pred = RF.predict(test_features_pca)\n",
    "        # compute the evaluation metrics and append to the respective list\n",
    "        RF_f1_scores[i, j] = f1_score(test_labels, y_pred)\n",
    "        RF_accuracy_scores[i, j] = accuracy_score(test_labels, y_pred)\n",
    "        RF_roc_auc_scores[i, j] = roc_auc_score(test_labels, y_pred)\n",
    "\n",
    "\n",
    "RF_f1 = np.mean(RF_f1_scores, axis=1)\n",
    "RF_accuracy = np.mean(RF_accuracy_scores, axis=1)\n",
    "RF_roc_auc = np.mean(RF_roc_auc_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9031392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_14ac4_row0_col0, #T_14ac4_row0_col1, #T_14ac4_row0_col2, #T_14ac4_row0_col3, #T_14ac4_row1_col0, #T_14ac4_row1_col1, #T_14ac4_row1_col2, #T_14ac4_row1_col3, #T_14ac4_row2_col0, #T_14ac4_row2_col1, #T_14ac4_row2_col2, #T_14ac4_row2_col3 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_14ac4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th id=\"T_14ac4_level0_col0\" class=\"col_heading level0 col0\" >KNN</th>\n",
       "      <th id=\"T_14ac4_level0_col1\" class=\"col_heading level0 col1\" >Logistic Regression</th>\n",
       "      <th id=\"T_14ac4_level0_col2\" class=\"col_heading level0 col2\" >LDA</th>\n",
       "      <th id=\"T_14ac4_level0_col3\" class=\"col_heading level0 col3\" >RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mislabeling Level</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_14ac4_level0_row0\" class=\"row_heading level0 row0\" >45%</th>\n",
       "      <td id=\"T_14ac4_row0_col0\" class=\"data row0 col0\" >0.34</td>\n",
       "      <td id=\"T_14ac4_row0_col1\" class=\"data row0 col1\" >0.42</td>\n",
       "      <td id=\"T_14ac4_row0_col2\" class=\"data row0 col2\" >0.42</td>\n",
       "      <td id=\"T_14ac4_row0_col3\" class=\"data row0 col3\" >0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14ac4_level0_row1\" class=\"row_heading level0 row1\" >50%</th>\n",
       "      <td id=\"T_14ac4_row1_col0\" class=\"data row1 col0\" >0.31</td>\n",
       "      <td id=\"T_14ac4_row1_col1\" class=\"data row1 col1\" >0.38</td>\n",
       "      <td id=\"T_14ac4_row1_col2\" class=\"data row1 col2\" >0.38</td>\n",
       "      <td id=\"T_14ac4_row1_col3\" class=\"data row1 col3\" >0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_14ac4_level0_row2\" class=\"row_heading level0 row2\" >55%</th>\n",
       "      <td id=\"T_14ac4_row2_col0\" class=\"data row2 col0\" >0.28</td>\n",
       "      <td id=\"T_14ac4_row2_col1\" class=\"data row2 col1\" >0.27</td>\n",
       "      <td id=\"T_14ac4_row2_col2\" class=\"data row2 col2\" >0.27</td>\n",
       "      <td id=\"T_14ac4_row2_col3\" class=\"data row2 col3\" >0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f9253e71f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dc41c_row0_col0, #T_dc41c_row0_col1, #T_dc41c_row0_col2, #T_dc41c_row0_col3, #T_dc41c_row1_col0, #T_dc41c_row1_col1, #T_dc41c_row1_col2, #T_dc41c_row1_col3, #T_dc41c_row2_col0, #T_dc41c_row2_col1, #T_dc41c_row2_col2, #T_dc41c_row2_col3 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dc41c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th id=\"T_dc41c_level0_col0\" class=\"col_heading level0 col0\" >KNN</th>\n",
       "      <th id=\"T_dc41c_level0_col1\" class=\"col_heading level0 col1\" >Logistic Regression</th>\n",
       "      <th id=\"T_dc41c_level0_col2\" class=\"col_heading level0 col2\" >LDA</th>\n",
       "      <th id=\"T_dc41c_level0_col3\" class=\"col_heading level0 col3\" >RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mislabeling Level</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc41c_level0_row0\" class=\"row_heading level0 row0\" >45%</th>\n",
       "      <td id=\"T_dc41c_row0_col0\" class=\"data row0 col0\" >0.62</td>\n",
       "      <td id=\"T_dc41c_row0_col1\" class=\"data row0 col1\" >0.81</td>\n",
       "      <td id=\"T_dc41c_row0_col2\" class=\"data row0 col2\" >0.81</td>\n",
       "      <td id=\"T_dc41c_row0_col3\" class=\"data row0 col3\" >0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc41c_level0_row1\" class=\"row_heading level0 row1\" >50%</th>\n",
       "      <td id=\"T_dc41c_row1_col0\" class=\"data row1 col0\" >0.50</td>\n",
       "      <td id=\"T_dc41c_row1_col1\" class=\"data row1 col1\" >0.60</td>\n",
       "      <td id=\"T_dc41c_row1_col2\" class=\"data row1 col2\" >0.60</td>\n",
       "      <td id=\"T_dc41c_row1_col3\" class=\"data row1 col3\" >0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc41c_level0_row2\" class=\"row_heading level0 row2\" >55%</th>\n",
       "      <td id=\"T_dc41c_row2_col0\" class=\"data row2 col0\" >0.38</td>\n",
       "      <td id=\"T_dc41c_row2_col1\" class=\"data row2 col1\" >0.18</td>\n",
       "      <td id=\"T_dc41c_row2_col2\" class=\"data row2 col2\" >0.18</td>\n",
       "      <td id=\"T_dc41c_row2_col3\" class=\"data row2 col3\" >0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f9123024c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5085a_row0_col0, #T_5085a_row0_col1, #T_5085a_row0_col2, #T_5085a_row0_col3, #T_5085a_row1_col0, #T_5085a_row1_col1, #T_5085a_row1_col2, #T_5085a_row1_col3, #T_5085a_row2_col0, #T_5085a_row2_col1, #T_5085a_row2_col2, #T_5085a_row2_col3 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5085a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th id=\"T_5085a_level0_col0\" class=\"col_heading level0 col0\" >KNN</th>\n",
       "      <th id=\"T_5085a_level0_col1\" class=\"col_heading level0 col1\" >Logistic Regression</th>\n",
       "      <th id=\"T_5085a_level0_col2\" class=\"col_heading level0 col2\" >LDA</th>\n",
       "      <th id=\"T_5085a_level0_col3\" class=\"col_heading level0 col3\" >RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mislabeling Level</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5085a_level0_row0\" class=\"row_heading level0 row0\" >45%</th>\n",
       "      <td id=\"T_5085a_row0_col0\" class=\"data row0 col0\" >0.56</td>\n",
       "      <td id=\"T_5085a_row0_col1\" class=\"data row0 col1\" >0.63</td>\n",
       "      <td id=\"T_5085a_row0_col2\" class=\"data row0 col2\" >0.63</td>\n",
       "      <td id=\"T_5085a_row0_col3\" class=\"data row0 col3\" >0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5085a_level0_row1\" class=\"row_heading level0 row1\" >50%</th>\n",
       "      <td id=\"T_5085a_row1_col0\" class=\"data row1 col0\" >0.50</td>\n",
       "      <td id=\"T_5085a_row1_col1\" class=\"data row1 col1\" >0.58</td>\n",
       "      <td id=\"T_5085a_row1_col2\" class=\"data row1 col2\" >0.58</td>\n",
       "      <td id=\"T_5085a_row1_col3\" class=\"data row1 col3\" >0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5085a_level0_row2\" class=\"row_heading level0 row2\" >55%</th>\n",
       "      <td id=\"T_5085a_row2_col0\" class=\"data row2 col0\" >0.43</td>\n",
       "      <td id=\"T_5085a_row2_col1\" class=\"data row2 col1\" >0.36</td>\n",
       "      <td id=\"T_5085a_row2_col2\" class=\"data row2 col2\" >0.36</td>\n",
       "      <td id=\"T_5085a_row2_col3\" class=\"data row2 col3\" >0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f92d199c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the results for each method and mislabeling level\n",
    "results_f1 = {\n",
    "    f'{mislabeling_level1}%': np.round([knn1_f1, log1_f1, LDA1_f1, rf1_f1], 2),\n",
    "    f'{mislabeling_level2}%': np.round([knn2_f1, log2_f1, LDA2_f1, rf2_f1], 2),\n",
    "    f'{mislabeling_level3}%': np.round([knn3_f1, log3_f1, LDA3_f1, rf3_f1], 2)\n",
    "}\n",
    "# Convert the results_f1 dictionary to a pandas dataframe\n",
    "df_f1 = pd.DataFrame.from_dict(results_f1, orient='index', columns=['KNN', 'Logistic Regression', 'LDA', 'RF'])\n",
    "# Rename the index\n",
    "df_f1.index.names = ['Mislabeling Level']\n",
    "# Rename the columns\n",
    "df_f1.columns.name = 'Method'\n",
    "# Center align the values in the dataframe\n",
    "# Center align the values in the dataframe\n",
    "df_f1 = df_f1.style.format(\"{:.2f}\").set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Print the dataframe\n",
    "print('F1 Scores:\\n')\n",
    "display(df_f1)\n",
    "\n",
    "#### for acc\n",
    "# Define the results for each method and mislabeling level\n",
    "results_acc = {\n",
    "    f'{mislabeling_level1}%': np.round([knn1_accuracy, log1_accuracy, LDA1_accuracy, rf1_accuracy], 2),\n",
    "    f'{mislabeling_level2}%': np.round([knn2_accuracy, log2_accuracy, LDA2_accuracy, rf2_accuracy], 2),\n",
    "    f'{mislabeling_level3}%': np.round([knn3_accuracy, log3_accuracy, LDA3_accuracy, rf3_accuracy], 2)\n",
    "}\n",
    "# Convert the results_acc dictionary to a pandas dataframe\n",
    "df_acc = pd.DataFrame.from_dict(results_acc, orient='index', columns=['KNN', 'Logistic Regression', 'LDA', 'RF'])\n",
    "# Rename the index\n",
    "df_acc.index.names = ['Mislabeling Level']\n",
    "# Rename the columns\n",
    "df_acc.columns.name = 'Method'\n",
    "# Center align the values in the dataframe\n",
    "df_acc = df_acc.style.format(\"{:.2f}\").set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Print the dataframe\n",
    "print('Accuracy:\\n')\n",
    "display(df_acc)\n",
    "\n",
    "\n",
    "#### for ROC AUC\n",
    "# Define the results for each method and mislabeling level\n",
    "results_auc = {\n",
    "    f'{mislabeling_level1}%': np.round([knn1_roc_auc, log1_roc_auc, LDA1_roc_auc, rf1_roc_auc], 2),\n",
    "    f'{mislabeling_level2}%': np.round([knn2_roc_auc, log2_roc_auc, LDA2_roc_auc, rf2_roc_auc], 2),\n",
    "    f'{mislabeling_level3}%': np.round([knn3_roc_auc, log3_roc_auc, LDA3_roc_auc, rf3_roc_auc], 2)\n",
    "}\n",
    "# Convert the results_auc dictionary to a pandas dataframe\n",
    "df_auc = pd.DataFrame.from_dict(results_auc, orient='index', columns=['KNN', 'Logistic Regression', 'LDA', 'RF'])\n",
    "\n",
    "df_auc.index.names = ['Mislabeling Level']\n",
    "# Rename the columns\n",
    "df_auc.columns.name = 'Method'\n",
    "# Center align the values in the dataframe\n",
    "df_auc = df_auc.style.format(\"{:.2f}\").set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Print the dataframe\n",
    "print('ROC AUC:\\n')\n",
    "display(df_auc)                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "18488ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83648426 0.8353843  0.81919428 0.83297814 0.83620927 0.83235941\n",
      "  0.8353843  0.8181287  0.81641001 0.8173381 ]\n",
      " [0.81266328 0.83101884 0.8339406  0.83868417 0.83026262 0.81610065\n",
      "  0.81651313 0.83442183 0.83366561 0.81544755]\n",
      " [0.8293689  0.82802832 0.82404097 0.81238829 0.82435034 0.82830331\n",
      "  0.82469407 0.80802282 0.80816032 0.82520968]\n",
      " [0.78622989 0.80121683 0.78492369 0.78619552 0.80589165 0.80369174\n",
      "  0.78468307 0.78574866 0.78667675 0.80427609]\n",
      " [0.70809845 0.69593015 0.69596453 0.70926715 0.6787433  0.70964526\n",
      "  0.7114327  0.70438609 0.69586141 0.70524543]\n",
      " [0.50309363 0.5        0.50257803 0.49618452 0.49924378 0.5014437\n",
      "  0.50508731 0.49319401 0.49388148 0.49054723]\n",
      " [0.30248866 0.30441358 0.31025712 0.29575141 0.29499519 0.31128833\n",
      "  0.29355149 0.30695724 0.29970439 0.29860443]\n",
      " [0.21710436 0.21425134 0.19531143 0.2005706  0.21583253 0.21170769\n",
      "  0.21397635 0.19476145 0.2132545  0.19266465]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(knn_accuracy_scores)\n",
    "# Create a numpy array with random data\n",
    "data = np.random.rand(10, 8)\n",
    "\n",
    "# Create a pandas dataframe from the numpy array\n",
    "df = pd.DataFrame(knn_accuracy_scores.T)\n",
    "df1 = pd.DataFrame(logreg_accuracy_scores.T)\n",
    "df2 = pd.DataFrame(LDA_accuracy_scores.T)\n",
    "\n",
    "# Optionally, you can name the columns of the dataframe based on the levels\n",
    "df.columns = ['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5', 'Level 6', 'Level 7', 'Level 8']\n",
    "df1.columns = ['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5', 'Level 6', 'Level 7', 'Level 8']\n",
    "df2.columns = ['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5', 'Level 6', 'Level 7', 'Level 8']\n",
    "# Create the sns.pointplot\n",
    "sns.pointplot(data=df)\n",
    "sns.pointplot(data=df1, color='red')\n",
    "sns.pointplot(data=df2, color='green')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb555d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_venv",
   "language": "python",
   "name": "bigdata_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
